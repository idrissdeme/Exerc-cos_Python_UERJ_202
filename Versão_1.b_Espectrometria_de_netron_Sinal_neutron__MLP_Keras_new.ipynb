{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idrissdeme/Exerc-cos_Python_UERJ_202/blob/main/Vers%C3%A3o_1.b_Espectrometria_de_netron_Sinal_neutron__MLP_Keras_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftxVZMcL9zlw"
      },
      "source": [
        "** MLP LEARNING NEUTRON SIGNAL **\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1MQaRXWLVxm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvoxEUZsXSpp"
      },
      "source": [
        "**Define the network hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo7CQ7KkFSud"
      },
      "outputs": [],
      "source": [
        "# Trainign batch size \n",
        "batch_size = 1\n",
        "# Number of training epochs\n",
        "epochs = 100\n",
        "# Fraction of the training data to be used as validation\n",
        "val_split = 0.3\n",
        "# Number of classes ( multi-classification )\n",
        "nb_classes = 1\n",
        "# Learning rate\n",
        "learning_rate=0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando arquivo teste"
      ],
      "metadata": {
        "id": "m_TBP8MJiWGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aKS-5q6n51qu",
        "outputId": "1a213eda-e727-4f3f-ed04-92e95cebe2d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install xlrd\n",
        "df= pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Dados_rede_MLP_Neutron.xlsx\")\n",
        "#df= pd.read_excel(\"/content/Dados_rede_MLP_Neutron.xlsx\")\n",
        "#pd.read_excel('/BASE de Teste_e_Treinamen 5.xls', engine='openpyxl')\n",
        "df= df.drop(columns=[\"Unnamed: 0\"])\n",
        "#df = df.dropna()\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "id": "nsNF1Hd3Db1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "1f6bde9e-8593-4297-dc26-dfbe3130b616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Entradas  Entradas.1  Entradas.2  Entradas.3  Entradas.4  Entradas.5  \\\n",
              "0    0.543861    0.201325    0.149053    0.074173    0.021294    0.002667   \n",
              "1    0.538087    0.201298    0.152657    0.075576    0.020753    0.003106   \n",
              "2    0.525730    0.205376    0.158838    0.076627    0.021271    0.003076   \n",
              "3    0.512739    0.207309    0.165742    0.079946    0.022347    0.003031   \n",
              "4    0.493597    0.218463    0.168312    0.083218    0.023865    0.003147   \n",
              "..        ...         ...         ...         ...         ...         ...   \n",
              "281  0.000077    0.001875    0.015979    0.108308    0.260462    0.313583   \n",
              "282  0.000068    0.001338    0.012946    0.093419    0.250006    0.327649   \n",
              "283  0.000063    0.001329    0.011869    0.088642    0.248518    0.347401   \n",
              "284  0.000055    0.001247    0.011018    0.086745    0.244663    0.342767   \n",
              "285  0.000051    0.001163    0.010063    0.080476    0.234558    0.356855   \n",
              "\n",
              "     Entradas.6  Saidas  Saidas.1  Saidas.2  ...  Saidas.74  Saidas.75  \\\n",
              "0             1       1       0.0       0.0  ...        0.0        0.0   \n",
              "1             2       0       1.0       0.0  ...        0.0        0.0   \n",
              "2             3       0       0.0       1.0  ...        0.0        0.0   \n",
              "3             4       0       0.0       0.0  ...        0.0        0.0   \n",
              "4             5       0       0.0       0.0  ...        0.0        0.0   \n",
              "..          ...     ...       ...       ...  ...        ...        ...   \n",
              "281          80       0       0.0       0.0  ...        0.0        0.0   \n",
              "282          81       0       0.0       0.0  ...        0.0        0.0   \n",
              "283          82       0       0.0       0.0  ...        0.0        0.0   \n",
              "284          83       0       0.0       0.0  ...        0.0        0.0   \n",
              "285          84       0       0.0       0.0  ...        0.0        0.0   \n",
              "\n",
              "     Saidas.76  Saidas.77  Saidas.78  Saidas.79  Saidas.80  Saidas.81  \\\n",
              "0          0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "1          0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "2          0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "3          0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "4          0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "281        0.0        0.0        0.0        1.0        0.0        0.0   \n",
              "282        0.0        0.0        0.0        0.0        1.0        0.0   \n",
              "283        0.0        0.0        0.0        0.0        0.0        1.0   \n",
              "284        0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "285        0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "\n",
              "     Saidas.82  Saidas.83  \n",
              "0          0.0        0.0  \n",
              "1          0.0        0.0  \n",
              "2          0.0        0.0  \n",
              "3          0.0        0.0  \n",
              "4          0.0        0.0  \n",
              "..         ...        ...  \n",
              "281        0.0        0.0  \n",
              "282        0.0        0.0  \n",
              "283        0.0        0.0  \n",
              "284        1.0        0.0  \n",
              "285        0.0        1.0  \n",
              "\n",
              "[286 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b0dee2e-0dce-45ca-8ca7-c61ca21c5c1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entradas</th>\n",
              "      <th>Entradas.1</th>\n",
              "      <th>Entradas.2</th>\n",
              "      <th>Entradas.3</th>\n",
              "      <th>Entradas.4</th>\n",
              "      <th>Entradas.5</th>\n",
              "      <th>Entradas.6</th>\n",
              "      <th>Saidas</th>\n",
              "      <th>Saidas.1</th>\n",
              "      <th>Saidas.2</th>\n",
              "      <th>...</th>\n",
              "      <th>Saidas.74</th>\n",
              "      <th>Saidas.75</th>\n",
              "      <th>Saidas.76</th>\n",
              "      <th>Saidas.77</th>\n",
              "      <th>Saidas.78</th>\n",
              "      <th>Saidas.79</th>\n",
              "      <th>Saidas.80</th>\n",
              "      <th>Saidas.81</th>\n",
              "      <th>Saidas.82</th>\n",
              "      <th>Saidas.83</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.543861</td>\n",
              "      <td>0.201325</td>\n",
              "      <td>0.149053</td>\n",
              "      <td>0.074173</td>\n",
              "      <td>0.021294</td>\n",
              "      <td>0.002667</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.538087</td>\n",
              "      <td>0.201298</td>\n",
              "      <td>0.152657</td>\n",
              "      <td>0.075576</td>\n",
              "      <td>0.020753</td>\n",
              "      <td>0.003106</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.525730</td>\n",
              "      <td>0.205376</td>\n",
              "      <td>0.158838</td>\n",
              "      <td>0.076627</td>\n",
              "      <td>0.021271</td>\n",
              "      <td>0.003076</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.512739</td>\n",
              "      <td>0.207309</td>\n",
              "      <td>0.165742</td>\n",
              "      <td>0.079946</td>\n",
              "      <td>0.022347</td>\n",
              "      <td>0.003031</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.493597</td>\n",
              "      <td>0.218463</td>\n",
              "      <td>0.168312</td>\n",
              "      <td>0.083218</td>\n",
              "      <td>0.023865</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>0.015979</td>\n",
              "      <td>0.108308</td>\n",
              "      <td>0.260462</td>\n",
              "      <td>0.313583</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.012946</td>\n",
              "      <td>0.093419</td>\n",
              "      <td>0.250006</td>\n",
              "      <td>0.327649</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.001329</td>\n",
              "      <td>0.011869</td>\n",
              "      <td>0.088642</td>\n",
              "      <td>0.248518</td>\n",
              "      <td>0.347401</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.001247</td>\n",
              "      <td>0.011018</td>\n",
              "      <td>0.086745</td>\n",
              "      <td>0.244663</td>\n",
              "      <td>0.342767</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.001163</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>0.080476</td>\n",
              "      <td>0.234558</td>\n",
              "      <td>0.356855</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b0dee2e-0dce-45ca-8ca7-c61ca21c5c1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b0dee2e-0dce-45ca-8ca7-c61ca21c5c1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b0dee2e-0dce-45ca-8ca7-c61ca21c5c1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[0:286, 0:7], df.iloc[0:286, 7:91], test_size=0.3, random_state=42)\n",
        "X_train = X_train.astype('double')\n",
        "X_test = X_test.astype('double')\n",
        "#print(X_train)\n",
        "#print(y_train)\n",
        "#print(X_test)"
      ],
      "metadata": {
        "id": "MrHlQX_YG7i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwHyt7p9FSun"
      },
      "source": [
        "# Load MNIST dataset (28x28 pixel images)\n",
        "#(X_train, y_train), (X_test, y_test) = df()\n",
        "\"\"\"X_train = X_train.values.reshape(100,14)\n",
        "X_test = X_test.values.reshape(2,301)\n",
        "X_train = X_train.astype('double')\n",
        "X_test = X_test.astype('double')\n",
        "#X_train /= 255\n",
        "X_test /= 255\n",
        "Y_Train = y_train/10.\n",
        "print(y_test)\n",
        "Y_Test = y_test/10.\n",
        "#print(Y_Test)\"\"\"\n",
        "\n",
        "\n",
        "x_train: (1,7*286)\n",
        "y_train: (1,84*286)\n",
        "#Y_Train = y_train/84.\n",
        "x_test: (1,7*286)\n",
        "y_test: (1,84*286)\n",
        "\n",
        "\n",
        "#X_train = X_train.values.reshape(X_train.shape[0], len(X_train))\n",
        "#X_test = X_test.reshape(X_test.shape[0], len(X_test))\n",
        "\n",
        "\n",
        "#Y_Test = y_test/84."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW5Ef_8PXtYs"
      },
      "source": [
        "**Define the MLP achitecture using KERAS sequential API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnEXAUWpFSus",
        "outputId": "a1dcf64b-5a00-473c-e175-4441928c5765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 50)                400       \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 25)                650       \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 25)                650       \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 25)                650       \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 25)                650       \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 84)                2184      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,515\n",
            "Trainable params: 6,515\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=7, activation=\"relu\", units=7, kernel_initializer=\"normal\"))\n",
        "model.add(Dense(activation=\"relu\", units=50, kernel_initializer=\"normal\")) # after first layer no need to specify input_dim\n",
        "model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\")) # after first layer no need to specify input_dim\n",
        "model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\"))\n",
        "model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\"))\n",
        "model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\"))\n",
        "model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\"))\n",
        "model.add(Dense(activation=\"relu\", units=84, kernel_initializer=\"normal\"))\n",
        "model.compile(optimizer=SGD(learning_rate=learning_rate), loss='mean_squared_error', metrics=['accuracy'])\n",
        "#model.compile(optimizer=SGD(learning_rate=learning_rate), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Uju_bZX45K"
      },
      "source": [
        "**Train the MLP**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"X_train\n",
        "X = np.array(X_train)\n",
        "len(X)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4mWW1IYFJ32d",
        "outputId": "7bf19860-791d-47d3-cdb0-37b794bc40d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X_train\\nX = np.array(X_train)\\nlen(X)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ZdRrtvFSu3",
        "outputId": "6158009c-faea-4729-8ee3-18e33fd89a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.0143 - val_loss: 0.0798 - val_accuracy: 0.0167\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.0286 - val_loss: 0.0740 - val_accuracy: 0.0333\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.0500 - val_loss: 0.0716 - val_accuracy: 0.0333\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.0500 - val_loss: 0.0707 - val_accuracy: 0.0333\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.0571 - val_loss: 0.0705 - val_accuracy: 0.0333\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.0571 - val_loss: 0.0705 - val_accuracy: 0.0333\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.0571 - val_loss: 0.0706 - val_accuracy: 0.0333\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.0571 - val_loss: 0.0707 - val_accuracy: 0.0333\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.0571 - val_loss: 0.0707 - val_accuracy: 0.0333\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 24/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 25/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 26/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 27/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 28/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 29/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 30/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 31/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 32/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 33/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 34/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 35/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 36/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 37/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 38/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 39/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 40/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 41/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 42/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 43/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 44/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 45/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 46/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 47/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 48/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 49/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 50/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 51/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 52/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 53/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 54/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 55/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 56/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 57/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 58/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 59/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 60/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 61/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 62/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 63/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 64/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 65/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 66/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 67/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 68/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 69/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 70/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 71/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 72/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 73/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0708 - val_accuracy: 0.0333\n",
            "Epoch 74/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 75/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 76/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 77/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 78/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 79/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 80/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 81/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 82/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 83/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 84/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 85/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 86/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 87/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 88/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 89/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0710 - val_accuracy: 0.0333\n",
            "Epoch 90/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 91/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 92/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 93/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 94/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 95/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 96/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 97/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 98/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 99/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n",
            "Epoch 100/100\n",
            "140/140 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.0571 - val_loss: 0.0709 - val_accuracy: 0.0333\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "#y=np.array(y_train)\n",
        "history = model.fit(X_train, y_train, validation_split=val_split, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "#history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87neTyT0X-1f"
      },
      "source": [
        "**Evaluate the MLP performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOlt7lO3FSvA",
        "outputId": "4762f968-cc73-4c11-cb5e-ff9a29f144f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0349\n",
            "Summary: Loss over the test dataset: 0.07, Accuracy: 0.03\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "evaluation = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEmgseziYHhS"
      },
      "source": [
        "**Plot the training and validation performances**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "2kdXNm_WFbME",
        "outputId": "7ecb3f6c-1e28-413f-feb8-4e1fac3d831c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3icdZ338fd3DplJ0iRt0wClLbTIQYpAkTyA6CoHXUFReFYREBVdVhZ3Fd1dV8Fdj9e6K14qyj4+6wkEPKGLy1ofERQBQRGkrAiUgtZSaEqhaXpIm+Ywh+/zx++ezCSdZGbaTpNmPq/rmmtm7uPvnnvm/szvPv3M3REREalWbKoLICIi+xcFh4iI1ETBISIiNVFwiIhITRQcIiJSEwWHiIjURMEhUidmttjM3MwSVQz7TjP71Z5OR2RfUHCIAGa21sxGzGzeuO6/izbai6emZCLTj4JDpOhp4KLCGzM7FmiZuuKITE8KDpGibwHvKHl/CXBT6QBm1mFmN5lZr5k9Y2b/bGaxqF/czD5nZpvMbA3w+jLjXmdmG8xsvZn9i5nFay2kmR1sZsvNbLOZrTazd5f0O8nMVphZv5m9YGZfiLqnzezbZtZnZlvN7CEzO7DWeYuAgkOk1ANAu5kdHW3QLwS+PW6Yfwc6gMOAVxGC5l1Rv3cD5wAnAN3Am8eNewOQBQ6Phvlz4K92o5w3Az3AwdE8/tXMzoj6fQn4kru3Ay8CfhB1vyQq9yKgE7gcGNyNeYsoOETGKdQ6XgOsAtYXepSEyVXuvt3d1wKfB94eDfIW4Ivuvs7dNwP/VjLugcDrgA+4+4C7bwSuiaZXNTNbBLwc+LC7D7n7I8A3KNaUMsDhZjbP3Xe4+wMl3TuBw9095+4Pu3t/LfMWKVBwiIz1LeCtwDsZt5sKmAckgWdKuj0DLIheHwysG9ev4NBo3A3RrqKtwFeBA2os38HAZnffPkEZLgWOBJ6MdkedU7JcdwA3m9lzZvZZM0vWOG8RQMEhMoa7P0M4SP464L/G9d5E+Od+aEm3QyjWSjYQdgWV9itYBwwD89x9dvRod/djaizic8BcM2srVwZ3/6O7X0QIpKuBW8ys1d0z7v5Jd18KnErYpfYORHaDgkNkV5cCZ7j7QGlHd88Rjhl82szazOxQ4O8pHgf5AXCFmS00sznAlSXjbgB+BnzezNrNLGZmLzKzV9VSMHdfB9wP/Ft0wPu4qLzfBjCzt5lZl7vnga3RaHkzO93Mjo12t/UTAjBfy7xFChQcIuO4+5/cfcUEvd8HDABrgF8B3wWuj/p9nbA76PfA/7BrjeUdQBPwBLAFuAWYvxtFvAhYTKh93Ap83N3vjPqdBaw0sx2EA+UXuvsgcFA0v37CsZtfEnZfidTM1JCTiIjUQjUOERGpiYJDRERqouAQEZGaKDhERKQmDXGb5nnz5vnixYunuhgiIvuVhx9+eJO7d43v3hDBsXjxYlasmOjsShERKcfMninXXbuqRESkJgoOERGpiYJDRERq0hDHOEREapXJZOjp6WFoaGiqi1J36XSahQsXkkxWd8NkBYeISBk9PT20tbWxePFizGyqi1M37k5fXx89PT0sWbKkqnG0q0pEpIyhoSE6OztndGgAmBmdnZ011awUHCIiE5jpoVFQ63IqOCZx4/1rWf7756a6GCIi04qCYxLfffBZbnt0w1QXQ0QaTF9fH8uWLWPZsmUcdNBBLFiwYPT9yMjIpOOuWLGCK664oq7l08HxSaSSMYayuakuhog0mM7OTh555BEAPvGJTzBr1iw++MEPjvbPZrMkEuU3393d3XR3d9e1fKpxTCKViDGcUeuaIjL13vnOd3L55Zdz8skn86EPfYjf/va3vOxlL+OEE07g1FNP5amnngLgnnvu4ZxzzgFC6PzlX/4lp512GocddhjXXnvtXimLahyTSCfj7BjOTnUxRGSKffLHK3niuf69Os2lB7fz8TccU9M4PT093H///cTjcfr7+7nvvvtIJBLceeedfOQjH+GHP/zhLuM8+eST3H333Wzfvp2jjjqK97znPVVfrzERBcckUokYfTtU4xCR6eH8888nHo8DsG3bNi655BL++Mc/YmZkMpmy47z+9a8nlUqRSqU44IADeOGFF1i4cOEelUPBMYlUMq5jHCJSc82gXlpbW0dff/SjH+X000/n1ltvZe3atZx22mllx0mlUqOv4/E42eye70XRMY5J6BiHiExX27ZtY8GCBQDccMMN+3TeCo5JpJNxhlXjEJFp6EMf+hBXXXUVJ5xwwl6pRdTC3H2fznAqdHd3++405PTJH6/klhU9PPbJ19ahVCIyna1atYqjjz56qouxz5RbXjN72N13ObdXNY5JpHWMQ0RkFwqOSaQSMTI5J5ef+bUyEZFqKTgmkU6G0950nENEpEjBMYlUInw8OrNKRKRIwTGJYo1DwSEiUqDgmEShxjGU0a4qEZECXTk+iVRCNQ4R2ff6+vo488wzAXj++eeJx+N0dXUB8Nvf/pampqZJx7/nnntoamri1FNPrUv5FByTSCdV4xCRfa/SbdUrueeee5g1a1bdgkO7qiahGoeITBcPP/wwr3rVqzjxxBN57Wtfy4YNoZG5a6+9lqVLl3Lcccdx4YUXsnbtWr7yla9wzTXXsGzZMu677769XhbVOCahGoeIAPDTK+H5x/buNA86Fs7+TFWDujvve9/7+NGPfkRXVxff//73+ad/+ieuv/56PvOZz/D000+TSqXYunUrs2fP5vLLL6+5llILBcckVOMQkelgeHiYxx9/nNe85jUA5HI55s+fD8Bxxx3HxRdfzHnnncd55523T8pT1+Aws7OALwFx4Bvu/plx/VPATcCJQB9wgbuvNbMm4KtAN5AH3u/u90TjnAjcADQDt0X96nJpt2ocIgJUXTOoF3fnmGOO4Te/+c0u/X7yk59w77338uMf/5hPf/rTPPbYXq4ZlVG3YxxmFge+DJwNLAUuMrOl4wa7FNji7ocD1wBXR93fDeDuxwKvAT5vZoWy/kfU/4jocVa9lkE1DhGZDlKpFL29vaPBkclkWLlyJfl8nnXr1nH66adz9dVXs23bNnbs2EFbWxvbt2+vW3nqeXD8JGC1u69x9xHgZuDcccOcC9wYvb4FONPMjBA0dwG4+0ZgK9BtZvOBdnd/IKpl3ATUrW6mGoeITAexWIxbbrmFD3/4wxx//PEsW7aM+++/n1wux9ve9jaOPfZYTjjhBK644gpmz57NG97wBm699db98uD4AmBdyfse4OSJhnH3rJltAzqB3wNvNLPvAYsIu7IWEXZb9Yyb5oJyMzezy4DLAA455JDdWgDVOERkqn3iE58YfX3vvffu0v9Xv/rVLt2OPPJIHn300bqVabqejns9IRRWAF8E7gdq+tvv7l9z92537y5cOFOrVFTj0E0ORUSK6lnjWE+oJRQsjLqVG6bHzBJAB9AX7Yb6u8JAZnY/8AdgSzSdyaa51xRvOaIah4hIQT1rHA8BR5jZkugsqQuB5eOGWQ5cEr1+M3CXu7uZtZhZK4CZvQbIuvsT7r4B6DezU6JjIe8AflSvBTAzmhIx1ThEGlQjtJAKtS9n3Woc0TGL9wJ3EE7Hvd7dV5rZp4AV7r4cuA74lpmtBjYTwgXgAOAOM8sTahRvL5n031A8Hfen0aNu0omYbqsu0oDS6TR9fX10dnYS/qfOTO5OX18f6XS66nHqeh2Hu99GuNaitNvHSl4PAeeXGW8tcNQE01wBvGSvFnQSqWRcNQ6RBrRw4UJ6enro7e2d6qLUXTqdZuHChZUHjOjK8QrSyZiOcYg0oGQyyZIlS6a6GNPSdD2ratpIJVTjEBEppeCoQDUOEZGxFBwVqMYhIjKWgqMC1ThERMZScFSgGoeIyFgKjgpU4xARGUvBUYFqHCIiYyk4KkgndeW4iEgpBUcFqURc7XGIiJRQcFSQSsTUHoeISAkFRwXhXlX5hrlLpohIJQqOCgptcqjWISISKDgqSCej5mN1gFxEBFBwVFSscegAuYgIKDgqKtQ4dBGgiEig4KhANQ4RkbEUHBWoxiEiMpaCowLVOERExlJwVKAah4jIWAqOClTjEBEZS8FRQSqpCwBFREopOCpIJwq7qlTjEBEBBUdFqnGIiIyl4KhANQ4RkbEUHBWoxiEiMpaCo4KUahwiImMoOCqIx4xk3FTjEBGJKDiqkFbzsSIioxQcVUgl1XysiEiBgqMKKdU4RERGKTiqoBqHiEiRgqMKqUScYdU4REQABUdV0qpxiIiMUnBUIZWIMazbqouIAAqOqqSTcYZ0W3UREaDOwWFmZ5nZU2a22syuLNM/ZWbfj/o/aGaLo+5JM7vRzB4zs1VmdlXJOGuj7o+Y2Yp6lr9ANQ4RkaK6BYeZxYEvA2cDS4GLzGzpuMEuBba4++HANcDVUffzgZS7HwucCPx1IVQip7v7Mnfvrlf5S6nGISJSVM8ax0nAandf4+4jwM3AueOGORe4MXp9C3CmmRngQKuZJYBmYATor2NZJ6Uah4hIUT2DYwGwruR9T9St7DDungW2AZ2EEBkANgDPAp9z983ROA78zMweNrPLJpq5mV1mZivMbEVvb+8eLYhqHCIiRdP14PhJQA44GFgC/IOZHRb1e4W7v5SwC+xvzeyV5Sbg7l9z92537+7q6tqjwqjGISJSVM/gWA8sKnm/MOpWdphot1QH0Ae8Fbjd3TPuvhH4NdAN4O7ro+eNwK2EkKmrQo3D3es9KxGRaa+ewfEQcISZLTGzJuBCYPm4YZYDl0Sv3wzc5WHr/CxwBoCZtQKnAE+aWauZtZV0/3Pg8TouAxBqHO6QySk4REQS9Zqwu2fN7L3AHUAcuN7dV5rZp4AV7r4cuA74lpmtBjYTwgXC2VjfNLOVgAHfdPdHo91Vt4bj5ySA77r77fVahoJ0MmrMKZujKTFd9+6JiOwbdQsOAHe/DbhtXLePlbweIpx6O368HRN0XwMcv/dLOrlUFBbDmTyk9/XcRUSmF/19roKajxURKVJwVCGVjGocutGhiIiCoxqFGsewruUQEVFwVCMd1TiGdC2HiIiCoxqqcYiIFCk4qlCocejqcRERBUdVVOMQESlScFRBxzhERIoUHFVIJVXjEBEpUHBUIZ1QjUNEpEDBUQXVOEREihQcVUipxiEiMkrBUYVkPEY8ZqpxiIig4KiaWgEUEQkUHFVSu+MiIoGCo0qqcYiIBAqOKoUah4JDRKSq4Ija+o5Fr480szeaWbK+RZteQo1Du6pERKqtcdwLpM1sAfAz4O3ADfUq1HSUUo1DRASoPjjM3XcCfwH8X3c/HzimfsWafpqTMQZHslNdDBGRKVd1cJjZy4CLgZ9E3eL1KdL01NGcZNtgZqqLISIy5aoNjg8AVwG3uvtKMzsMuLt+xZp+FBwiIkGimoHc/ZfALwGig+Sb3P2KehZsulFwiIgE1Z5V9V0zazezVuBx4Akz+8f6Fm16aU8nGcrkddsREWl41e6qWuru/cB5wE+BJYQzqxpGR0s4+7h/UAfIRaSxVRscyei6jfOA5e6eAbx+xZp+OppDcGh3lYg0umqD46vAWqAVuNfMDgX661Wo6ahdwSEiAlR/cPxa4NqSTs+Y2en1KdL0VKhx9Cs4RKTBVXtwvMPMvmBmK6LH5wm1j4ahXVUiIkG1u6quB7YDb4ke/cA361Wo6UjBISISVLWrCniRu7+p5P0nzeyRehRoulJwiIgE1dY4Bs3sFYU3ZvZyYLA+RZqekvEYLU1xBYeINLxqaxyXAzeZWUf0fgtwSX2KNH11NCd1cFxEGl61Z1X9HjjezNqj9/1m9gHg0XoWbrppT+u2IyIiNbUA6O790RXkAH9fh/JMa7pflYjInjUda3utFPuJdgWHiMgeBUfFW46Y2Vlm9pSZrTazK8v0T5nZ96P+D5rZ4qh70sxuNLPHzGyVmV1V7TTrScc4REQqHOMws+2UDwgDmiuMGwe+DLwG6AEeMrPl7v5EyWCXAlvc/XAzuxC4GrgAOB9IufuxZtZCuBvv94B1VUyzbrSrSkSkQo3D3dvcvb3Mo83dKx1YPwlY7e5r3H0EuBk4d9ww5wI3Rq9vAc40MyOEVauZJQgBNUK46LCaadZNR3OSgZEcmZzaHheRxrUnu6oqWUCoIRT0RN3KDuPuWWAb0EkIkQFgA/As8Dl331zlNAEws8sKt0jp7e3dvSV49D/hjz8ffdvRHLJSu6tEpJHVMzj2xElADjiY0PbHP0TN1VbN3b/m7t3u3t3V1bV7pbjv8/DwDaNvC21yaHeViDSyegbHemBRyfuFUbeyw0S7pTqAPuCtwO3unnH3jcCvge4qp7n3pDtguHj3+NE75A6pMScRaVz1DI6HgCPMbImZNQEXAsvHDbOc4hXobwbucncn7J46AyBqrvYU4Mkqp7n3pNthqBgc7WnVOERE6hYc0TGL9wJ3AKuAH7j7SjP7lJm9MRrsOqDTzFYTLigsnF77ZWCWma0khMU33f3RiaZZr2Ug1V62xqHgEJFGVu29qnaLu98G3Dau28dKXg8RTr0dP96Oct0nmmbdpNthaNvoWwWHiMj0PTg+PaQ7wq4qD5eytKsVQBERBcekUu2Qz0B2CIB0Mk4qEVONQ0QamoJjMun28Dw09jjHtp0KDhFpXAqOyaSi5kfGHSBXjUNEGpmCYzLpKDjGHSDvH1JwiEjjUnBMZnRX1djgUI1DRBqZgmMyqSg4tKtKRGSUgmMyZQ6OqzEnEWl0Co7JlDnG0d6cZPtQlly+YjtWIiIzkoJjMk2zwGJlbzuyXQfIRaRBKTgmYwaptl2u4wDddkREGpeCo5JU+VurKzhEpFEpOCpJd+hGhyIiJRQclYxrk2O0MadBNeYkIo1JwVFJqh2GVeMQESlQcFQyQY1DwSEijUrBUUlqbGNO6WSMprhurS4ijUvBUUm6A4a3jzbmZGa0NycUHCLSsBQclaTbwXMwMjDaqb05qVYARaRhKTgq0Y0ORUTGUHBUMsGt1bcOjkxRgUREppaCo5LRGx0WaxzzO9Js2Do0RQUSEZlaCo5KyjQfe8jcVvoGRnSjQxFpSAqOSsrsqjq0swWAZ/p2TkWJRESmlIKjkjIHxwvB8exmBYeINB4FRyVlGnM6tLMVUI1DRBqTgqOSZDPEEmMOjs9KJehsbeLZzQOTjCgiMjMpOCoxi2502D+m8yGdLapxiEhDUnBUY9yNDgEWd7YqOESkISk4qjGuMSeAQ+a28Ny2QYazuSkqlIjI1FBwVKPMrqpDO1twh54tg1NUKBGRqaHgqEa6Y5ddVaOn5Gp3lYg0GAVHNcodHJ9bOCVXZ1aJSGNRcFSjzDGOebOaaG2Ks1Y1DhFpMAqOaqTbQ2NO+fxoJzPjkM5WXT0uIg2nrsFhZmeZ2VNmttrMrizTP2Vm34/6P2hmi6PuF5vZIyWPvJkti/rdE02z0O+Aei4DEN12xGFk+5jOh85t0a4qEWk4dQsOM4sDXwbOBpYCF5nZ0nGDXQpscffDgWuAqwHc/TvuvszdlwFvB55290dKxru40N/dN9ZrGUaN3uhw1wPk6zYPkst73YsgIjJd1LPGcRKw2t3XuPsIcDNw7rhhzgVujF7fApxpZjZumIuicadOmftVQbhn1Uguz/P9aptDRBpHPYNjAbCu5H1P1K3sMO6eBbYBneOGuQD43rhu34x2U320TNAAYGaXmdkKM1vR29u7u8sQlLlDLpTeXl27q0SkcUzrg+NmdjKw090fL+l8sbsfC/xZ9Hh7uXHd/Wvu3u3u3V1dXXtWkAl2VR0yV9dyiEjjqWdwrAcWlbxfGHUrO4yZJYAOoK+k/4WMq224+/roeTvwXcIusfoq0wogwMGzm0nGjWd0ZpWINJB6BsdDwBFmtsTMmgghsHzcMMuBS6LXbwbucncHMLMY8BZKjm+YWcLM5kWvk8A5wOPUW5lWAAHiMWPhnBbVOESkoSTqNWF3z5rZe4E7gDhwvbuvNLNPASvcfTlwHfAtM1sNbCaES8ErgXXuvqakWwq4IwqNOHAn8PV6LUNxruWDA8JxjrU6xiEiDaRuwQHg7rcBt43r9rGS10PA+ROMew9wyrhuA8CJe72glSTTEE/tsqsK4KgD27h/dR87hrPMStX14xQRmRam9cHxaaVMmxwAp7/4AEZyee77wx6euSUisp9QcFSrzI0OAboPnUNHc5I7V9X/OkQRkelAwVGtMjc6BEjEY5x+VBd3P7VRV5CLSENQcFSr7SDo31C216uXHsjmgRF+9+yWfVwoEZF9T8FRrTlLYPMa8F1rFa88sotEzPj5qhemoGAiIvuWgqNac5dAdhC2P79Lr/Z0klMO6+TOJxQcIjLzKTiqNfew8Lx5TdneZx59AH/qHeDpTbqmQ0RmNgVHtSoEx6uPPhCAX2h3lYjMcAqOanUsglhiwuBYNLeFFx/Uxs+1u0pEZjgFR7XiCZh96ITBAXD2S+bz4NObeWjt5n1YMBGRfUvBUYu5h00aHH/1Z0tYMLuZD//wUYYyuX1YMBGRfUfBUYu5h8Hmp8uekgvQmkrwb39xLGt6B7j2F3/cx4UTEdk3FBy1mHsYjGyHgU0TDvLKI7t484kL+eq9a3h8/a5XmouI7O8UHLWocGZVwUdfv5S5rU188D9/T9+O4X1QMBGRfUfBUYsqg6OjJcln33QcazYN8Lpr7+OBNX2TDi8isj9RcNRi9iFgsYrBAeF26//9Ny+ntSnBW7/+AF/42VP0blftQ0T2f2p5qBaJpnA9RxXBAbD04HaWv+8V/POtj3HtXav597tX878Oncurlx7AUQe1s7izhQWzm0nEld8isv9QcNSqwim5481KJfjihSdw+Wkv4vbHn+f2x5/nX297crR/PGbMbk4yuyXJnJYmWlIJWpJxmpviuDuZvJPN5Ukn48xKJZiVSpB3Z+dIjsGRHDl3DIiZYWbEY4XXkM356K3emxIxmhIxmpvizG5uYnZLkmQ8xqYdw/RuH2brzgwxC+WJxYx83sm7k8uDu+NAPjqbLGaGRWVPxGMkYgaA42NOOHMgn3dGcnmyudAjEU0/ETPi0QMgk8sznM3jHqafiIVlGC0DjmHEDMwglCC8TkefVyoRYzCTY8dQlp0jOcygKR4jETcSsdjoPJ3w2eQ9PNzD9AvLFjMj704276Ofw+gyOeS9+JkAoSRW/FzMiifeeTSO41DSjXHjFpYnfCcgHouRjNtoeeIxyOTCZzmSzY+WqfCZFNZbzArli9aI73oSoOOjwzhOIlqPyeizKXTPO6PLXyhPIhYj706mZJ3GYmBmo/PM58N6K0zLjNEyQlivo8tqxe9BUyJGUzxGzIyBkSwDw1kGMzksGidmoRmDpniMeMzI5Z1sPl/SnEFxuHj0e3APy5Eb/e6G9eRRt3zeMbPRZTNjdLrujJattJwA2Xz4DNwhlYiRTsZJxo2BkRwDw1mGMjmS8RipRJxkIswvk8uPaXrBCr+RqIyFeSTjNvo9y49beYXlybsTs/CZpRKh3CPZ8BvK5PJjxvnUuS8huZf/nCo4ajX3MHj8hzWP9uKD2nnxQe184NVH0rt9mKc3DbB20wDPbt7J5p0jbN05wpaBDNt2jrBhJMfOkVy0YTaSsRhD2bBB3D6cJW5GS1OcdDJOYvRL5qPPuXz40SZjRjzqP5LNM5LLs3M4x8i4L1ZrU5yO5iRO+NHkvfhDL4RQ4RkYM59sFGwQNh6FDWdBzIxkPGx0IPxYC4FW2DhD2MAn4zFiMcjnGe1fKENB4YdTkHdnKJNjMJMjk3OaEjHaUglaUnHyecjm82RyoYyF8saiH2jMIBYrlNlGp5/Le3GDMW7+hWWKxcJG28dtnAvrIYQbo58L0edSmFS5cUuXKZMLG698tD5yeScRN1KFjWvMxsyz8HkV1l1hI1pYH6XBFJahWK7ChjKT85JxCqEVljcbDZPNOTELf0TiMcOw0QCmJNiLIVqcR37cuoNQ7sJjJBfKAJBOxmhtSpBOxses99L1WfjjUtiYjwZXyfezdBlC3+JGt9C9MN1c9Gei9M9QzseWsbB+E/HwvTZgONpgQ/hj1JpKkE7GyOac4eh3F4/+DMXjNhoY7sUgsyjwC4Fso+E39rsZixXXSy7vo7/rfBRgqUSMRFSugo+/wYk+xr1GwVGruYfB0FbYuRla5u7WJLraUnS1pThpye6NvyfcnaFMnq2DI4xk88yblaJ1hrSVXtjgy/4rH/3p2d/WYz76U5KM2+iGfiabGVuMfWn0zKqndzs4ppKZ0dwUp7mpeaqLstftbxsb2VVsP12HsZjRtJ+WfXfoqGytqjwlV0RkplJw1GrOYsAUHCLSsBQctUqmoX2BgkNEGpaCY3fMXQKb/jDVpRARmRIKjt2x5JXw3P/AlmemuiQiIvucgmN3HH8RYPDId6a6JCIi+5yCY3fMXgQvOgN+9x3Iq8EmEWksCo7ddcLboL8H1twz1SUREdmndAHg7nrx66F5Dvzu23D4mVNdmtptWw8vrIR8FjwHuQwMbw+P7BDMOgDaDoa2A6G1C5rnhps8ViOXhe3PwdZnwfPQ1ArJ1jCvoa0wtA3iqXC34dmLIDnzLkbcRT4HIzvC3ZVjifDIjUB2OHze+WwYxvPQdlD4zKR2wzsg2RJuoFUqlwU8fO4TXdlduIfL+P7ZYcgMRusoG9ZbLhO6D22F3qeg90noXw+zDgxnXc4+BBadFJ73xERlmmIKjt2VSMFxF8CK6/fo9iNVyQzC+ofhmfvh2QfCFzfVDumOaGNuYYOU2RlaJ9zZBzi0dIZH85wwfKoNBnph9Z2w8Ynay5Fqh+bZxellh2AwCgLPhzKYhfnns9VPt6kNYvHwSKQhHc0j0RSmPbQtfAaJFCSaQ9Ck2iDdHobtWBR+oB0LQhnyWcgMQd9q6F0FfX8K0+s8PFzAGUuEzyqzE7a/ANvWwbaesBEYGQiPXKZYvlh87LybWsP848lQrszOsGFKNIVhYgnIDoYyjOyIwrKfsbc3rKBtPsx9Ecw5NGyIOhaGz3hnX3gM9YfWKEcGwsZyZCC8txi0zIPWedA0K4zjechnQnmyQ2HZYgmIJ0KAN7WGRywRPu9vlkIAAAsMSURBVIcta8NzYR2aQesB0H4wtM8PATe0LfzJyGXGblAzO8N8cIglw2dnsfDeHeJN4TuUnh0+r8xgeMST0HU0HLg0rM+RHcV5jIZq9AcnNxLNK1qezE7ofy6Uebg/zKPwmY3sCP12bAxlsFhY5kQqrMtEOkx7uD/My/PF7hDGz41UXl/JljDPp+8N5S5oXwgLXhpCZscL4feZTIffbqotCp9o3rE4pGaF9TayA3b0ws5NYPEQSLMOCMMMbgm/u1g8XFc2+9DwW9i5OXw3hvuLn1k+C399X/V/+qpkPkH72TNJd3e3r1ixYu9P+PnH4CuvgLM/Cyf/de3jZ4fDab2b/hA2blueCf+UmmaFL/+WtbBxVdgAeg4wOPCYsNEe2ha+INlhwo8yH/7Vt8wNYWFW/CINbglfzMKP+ZBT4Ig/h0Unhx+QxcIPN9UWbRCbwg9t+/OwfUO0sdocvsSDW8P0hraFH1jz7FCeWKK4kWrtKtYm4k3Rxm17mEd6dvjRZIfC8m59JkyvsGHIDIUN7eDWsPFNd4Rxki1hnOxQcXrD/WHcgd6JP+OWTug8AgY3h9vE5DNj+ydbwgamfUG0sY1qR/FkcZh8tlgzyAyGH/VwtEEpBEksDtmRYu0hkQ79ks0htAphi0cb21z4McdT4bmwkYXwz7VvDWz+E2xdF9ZBaegkW8Pn3tQaviuFIGtqDZ//wKawvgpBYiWhnIyCLZ8Ln0VupBiW2eHwWcxZHNZfPNrYeC58H/rXQ/+G0L3wXUmkonCIj11msxCm+UzxFrmF73xh/eZGwuff1Brmv3EV7Hi+zEq0knmkotBrChvgwjzbDo7W4/zwndi6LpQ31RYCr21++IxzUe0hNxKes0Ohe6otbLQtHoX+YJh106zQPdkShosnwnMiFcrQNAvmHRHCrlDLGd4R1t2zD8Kz98Nzj4Tptx0UQj03HP0h6g/TKYRIPlv8bje1ht9Ra1fovmNj+Gw8H2r/zXPCMmx5JmwnRrYX/yim2qLvUyJ8bm/6RpjPbjCzh929e5fuCo499NVXhY3SRTeHjfpE3MMKXvurUGvY8PtQvS3dkLXND1+MkZ3hy9uxCA5YCgccDQu7wwa/ec7ulTOfh8xA+GE0tezeNKarzGBxQ2EW/cCTMGcJzOoqDpfLhmHwsPEtbPSn2W6AXeQyITwsHv4YzORdewN9YTdnoUadaisGquxzCo56BcfaX8MP3hH+/Z52JZz6/vCvJDsSguKZX4ddTM/8OtpoEf4xHHwCzD8ODjoW5h0VdqHMtA26iOzXFBz1Cg4IuwZ+8vfwxI+iquhICJKC1gPg0FNh8SvCo+vF0/9frog0vImCQwfH94bWefCWm2DlrfDU7WH/c0tn2PV0yMug80UKChGZMeoaHGZ2FvAlIA58w90/M65/CrgJOBHoAy5w97VmdjHwjyWDHge81N0fMbMTgRuAZuA24P0+XapNx/zv8BARmcHqdgGgmcWBLwNnA0uBi8xs6bjBLgW2uPvhwDXA1QDu/h13X+buy4C3A0+7+yPROP8BvBs4InqcVa9lEBGRXdXzyvGTgNXuvsbdR4CbgXPHDXMucGP0+hbgTNu13cWLonExs/lAu7s/ENUybgLOq9cCiIjIruoZHAuAdSXve6JuZYdx9yywDegcN8wFwPdKhu+pME0AzOwyM1thZit6eyc5z19ERGoyre9VZWYnAzvd/fFax3X3r7l7t7t3d3V1VR5BRESqUs/gWA8sKnm/MOpWdhgzSwAdhIPkBRdSrG0Uhl9YYZoiIlJH9QyOh4AjzGyJmTURQmD5uGGWA5dEr98M3FU4Q8rMYsBbiI5vALj7BqDfzE6JjoW8A/hRHZdBRETGqdvpuO6eNbP3AncQTse93t1XmtmngBXuvhy4DviWma0GNhPCpeCVwDp3H9+4999QPB33p9FDRET2EV05LiIiZTX0LUfMrBfY3QbC5wGb9mJx9geNuMzQmMvdiMsMjbncu7PMh7r7LmcXNURw7AkzW1EucWeyRlxmaMzlbsRlhsZc7r25zNP6dFwREZl+FBwiIlITBUdlX5vqAkyBRlxmaMzlbsRlhsZc7r22zDrGISIiNVGNQ0REaqLgEBGRmig4JmBmZ5nZU2a22syunOry1IuZLTKzu83sCTNbaWbvj7rPNbOfm9kfo+c5U13Wvc3M4mb2OzP7f9H7JWb2YLTOvx/dKmdGMbPZZnaLmT1pZqvM7GUzfV2b2d9F3+3Hzex7ZpaeievazK43s41m9nhJt7Lr1oJro+V/1MxeWsu8FBxlVNkI1UyRBf7B3ZcCpwB/Gy3rlcAv3P0I4BfR+5nm/cCqkvdXA9dEDYttITQ0NtN8Cbjd3V8MHE9Y/hm7rs1sAXAF0O3uLyHc/uhCZua6voFdG7abaN2eTbExvMsIDeRVTcFRXjWNUM0I7r7B3f8ner2dsCFZwNhGtm5khjWYZWYLgdcD34jeG3AGoUExmJnL3EG4B9x1AO4+4u5bmeHrmnBPvuboDtwtwAZm4Lp293sJ9/wrNdG6PRe4yYMHgNlRQ3lVUXCUV00jVDOOmS0GTgAeBA6M7kYM8Dxw4BQVq16+CHwIyEfvO4GtUYNiMDPX+RKgF/hmtIvuG2bWygxe1+6+Hvgc8CwhMLYBDzPz13XBROt2j7ZxCg4BwMxmAT8EPuDu/aX9olvdz5jzts3sHGCjuz881WXZxxLAS4H/cPcTgAHG7Zaaget6DuHf9RLgYKCVXXfnNIS9uW4VHOVV0wjVjGFmSUJofMfd/yvq/EKh6ho9b5yq8tXBy4E3mtlawm7IMwj7/mdHuzNgZq7zHqDH3R+M3t9CCJKZvK5fDTzt7r3ungH+i7D+Z/q6Lpho3e7RNk7BUV41jVDNCNG+/euAVe7+hZJepY1sXcIMajDL3a9y94Xuvpiwbu9y94uBuwkNisEMW2YAd38eWGdmR0WdzgSeYAava8IuqlPMrCX6rheWeUav6xITrdvlwDuis6tOAbaV7NKqSFeOT8DMXkfYD15ohOrTU1ykujCzVwD3AY9R3N//EcJxjh8AhxBuSf8Wdx9/4G2/Z2anAR9093PM7DBCDWQu8Dvgbe4+PJXl29vMbBnhhIAmYA3wLsIfyBm7rs3sk8AFhDMIfwf8FWF//oxa12b2PeA0wu3TXwA+Dvw3ZdZtFKL/h7DbbifwLnevutEiBYeIiNREu6pERKQmCg4REamJgkNERGqi4BARkZooOEREpCYKDpG9wMxyZvZIyWOv3SjQzBaX3vFUZKolKg8iIlUYdPdlU10IkX1BNQ6ROjKztWb2WTN7zMx+a2aHR90Xm9ldUVsIvzCzQ6LuB5rZrWb2++hxajSpuJl9PWpX4mdm1jxlCyUNT8Ehsnc0j9tVdUFJv23ufizhSt0vRt3+HbjR3Y8DvgNcG3W/Fvilux9PuI/Uyqj7EcCX3f0YYCvwpjovj8iEdOW4yF5gZjvcfVaZ7muBM9x9TXQzyefdvdPMNgHz3T0Tdd/g7vPMrBdYWHr7i+h29z+PGuPBzD4MJN39X+q/ZCK7Uo1DpP58gte1KL2PUg4dn5QppOAQqb8LSp5/E72+n3BnXoCLCTeahNC853tgtE30jn1VSJFq6V+LyN7RbGaPlLy/3d0Lp+TOMbNHCbWGi6Ju7yO0xPePhFb53hV1fz/wNTO7lFCzeA+h5TqRaUPHOETqKDrG0e3um6a6LCJ7i3ZViYhITVTjEBGRmqjGISIiNVFwiIhITRQcIiJSEwWHiIjURMEhIiI1+f+yu5UDeJbOOgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training History Visualization\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CÃ³pia de VersÃ£o 1. Espectrometria de netron- Sinal-neutron_ MLP_Keras_new.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}